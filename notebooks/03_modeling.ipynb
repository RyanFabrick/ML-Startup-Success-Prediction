{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d071870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, precision_recall_curve,\n",
    "    roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09ad4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f2bda",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data\n",
    "\n",
    "### Loading Logic\n",
    "\n",
    "- Stratified splits for academic replication\n",
    "- Scaled versions for SVM algorithms\n",
    "- Proper Series conversion for target variables\n",
    "\n",
    "### Data Integrity\n",
    "\n",
    "- Training: 28,860 samples × 22 features\n",
    "- Test: 7,215 samples × 22 features\n",
    "- Balanced success rates (7.72% both splits)\n",
    "- Feature categories sum correctly (3 + 15 + 4 = 22)\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- This follows the academic replication strategy from previous preprocessing and feature engineering notebook, using stratified splits to match Żbikowski & Antosiuk (2021) methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72524ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Academic Paper Replication Modeling\n",
      "Loading processed data first\n",
      "Loading sclaed versions for SVM second\n",
      "Training set: 28,860 samples, 22 features\n",
      "Test set: 7,215 samples, 22 features\n",
      "Training success rate: 7.72%\n",
      "Test success rate: 7.72%\n",
      "\n",
      "Feature breakdown:\n",
      "- Geographic features: 3\n",
      "- Industry features: 15\n",
      "- Temporal features: 4\n",
      "- Total features: 22\n"
     ]
    }
   ],
   "source": [
    "# Loading Data for Academic Paper Replication Modeling\n",
    "\n",
    "print(\"Loading Data for Academic Paper Replication Modeling\")\n",
    "\n",
    "# Loads the stratified splits (academic paper replication)\n",
    "print(\"Loading processed data first\")\n",
    "X_train = pd.read_csv('../data/processed/X_train_stratified.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test_stratified.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train_stratified.csv').iloc[:, 0]  # Convert to Series\n",
    "y_test = pd.read_csv('../data/processed/y_test_stratified.csv').iloc[:, 0]    # Convert to Series\n",
    "\n",
    "# Loads scaled versions for SVM\n",
    "print(\"Loading sclaed versions for SVM second\")\n",
    "X_train_scaled = pd.read_csv('../data/processed/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('../data/processed/X_test_scaled.csv')\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples, {X_test.shape[1]} features\")\n",
    "print(f\"Training success rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test success rate: {y_test.mean()*100:.2f}%\")\n",
    "\n",
    "# Feature categories for analysis\n",
    "geographic_features = ['region_startup_density', 'city_startup_density', 'is_usa']\n",
    "industry_features = [col for col in X_train.columns if col.startswith('category_')]\n",
    "temporal_features = ['founded_year_std', 'era_dotcom_era', 'era_post_crash', 'era_recovery']\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"- Geographic features: {len(geographic_features)}\")\n",
    "print(f\"- Industry features: {len(industry_features)}\")\n",
    "print(f\"- Temporal features: {len(temporal_features)}\")\n",
    "print(f\"- Total features: {len(geographic_features) + len(industry_features) + len(temporal_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90ec65",
   "metadata": {},
   "source": [
    "## 2. Baseline Model Setup\n",
    "\n",
    "### Cross Validation Strategy\n",
    "\n",
    "- 5 fold stratified CV is a proper choice for imbalanced dataset (7.72% success rate)\n",
    "- shuffle=True with random_state=42 ensures reproducible results\n",
    "- Stratification maintains class balance across all folds\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- Proper choices for imbalanced classification: precision, recall, f1, roc_auc\n",
    "- Matches academic paper's (Żbikowski & Antosiuk (2021)) evaluation framework\n",
    "- Avoids accuracy (it would be misleading with 92.28% negative class)\n",
    "\n",
    "### Academic Benchmarks\n",
    "\n",
    "- Are correctly extracted from Żbikowski & Antosiuk (2021)\n",
    "- Clear performance targets for validation\n",
    "- F1-score of 43% reflects the precision/recall balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c32f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Setup\n",
      "Cross-validation: 5-fold stratified\n",
      "Evaluation metrics: ['precision', 'recall', 'f1', 'roc_auc']\n",
      "\n",
      "Academic targets to match/exceed:\n",
      "- Precision: 57%\n",
      "- Recall: 34%\n",
      "- F1-Score: 43%\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model Setup/Configuration\n",
    "\n",
    "print(\"Baseline Model Setup\")\n",
    "\n",
    "# Sets up cross validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Cross-validation: 5-fold stratified\")\n",
    "\n",
    "# Defines scoring metrics (academic paper replication metrics)\n",
    "scoring_metrics = ['precision', 'recall', 'f1', 'roc_auc']\n",
    "print(f\"Evaluation metrics: {scoring_metrics}\")\n",
    "\n",
    "# Academic targets from academic paper: Żbikowski & Antosiuk (2021)\n",
    "TARGET_PRECISION = 0.57\n",
    "TARGET_RECALL = 0.34\n",
    "TARGET_F1 = 0.43\n",
    "\n",
    "print(f\"\\nAcademic targets to match/exceed:\")\n",
    "print(f\"- Precision: {TARGET_PRECISION:.0%}\")\n",
    "print(f\"- Recall: {TARGET_RECALL:.0%}\")\n",
    "print(f\"- F1-Score: {TARGET_F1:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43eeb0",
   "metadata": {},
   "source": [
    "## 3. MODEL 1: Logistic Regression (With Regularization)\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Hyperparameter Grid Implementation**: Designed systematic parameter space exploration covering regularization strength (C: 0.001-100), penalty types (L1/L2), class weighting strategies (None/balanced), and solver configuration (liblinear) to identify optimal model configuration for imbalanced startup classification task\n",
    "- **Grid Search Cross-Validation Execution**: Applied 5 fold stratified cross validation across 24 hyperparameter combinations (120 total model fits), optimizing for F1-score to balance precision-recall tradeoffs critical for startup success prediction where both false positives and false negatives carry significant business costs\n",
    "- **Optimal Configuration Selection**: Identified best performing parameters through systematic evaluation: C=1 (moderate regularization), L1 penalty (feature selection capability), balanced class weighting (addressing 7.72% positive class imbalance), and liblinear solver (efficient for L1/L2 penalties)\n",
    "- **Model Evaluation Pipeline**: Executed comprehensive performance assessment using test set predictions, calculating precision (16.9%), recall (70.9%), F1-score (27.3%), and AUC-ROC (78.1%) metrics against academic benchmarks from Żbikowski & Antosiuk (2021) research\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Academic Replication Compliance**: Applied identical evaluation framework to published research methodology, enabling direct performance comparison with established benchmarks (57% precision, 34% recall, 43% F1-score) while maintaining consistent cross validation and scoring approaches\n",
    "- **Imbalanced Classification Optimization**: Implemented balanced class weighting to address severe class imbalance (92.28% negative class), preventing model bias toward majority class predictions that would achieve high accuracy but fail to identify startup success patterns\n",
    "- **Regularization Strategy Selection**: L1 penalty selection enables automatic feature selection during training, identifying most predictive features among 22 founding time variables while preventing overfitting in high dimensional feature space relative to positive class sample size\n",
    "- **F1-Score Optimization Focus**: Targeted F1-score maximization during hyperparameter tuning to achieve optimal precision recall balance, reflecting real world venture capital decision-making where both missed opportunities (false negatives) and wasted due diligence (false positives) impose significant costs\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Recall Excellence vs Precision Challenge**: Achieved exceptional recall performance (70.9%) exceeding academic target by 2.1x, successfully identifying 71% of actual startup successes, but suffered from low precision (16.9%) indicating high false positive rate with only 17% of positive predictions being correct\n",
    "- **Class Imbalance Impact**: Balanced class weighting strategy effectively addressed minority class detection but created precision recall tradeoff where model sensitivity improvement came at cost of prediction specificity, resulting in 83% false positive rate among predicted successes\n",
    "- **Discriminative Capability Validation**: Strong AUC-ROC performance (78.1%) demonstrates robust ranking ability to distinguish successful from unsuccessful startups, indicating feature set contains meaningful predictive signals despite precision challenges\n",
    "- **Academic Benchmark Comparison**: Performance gap relative to published targets (F1: 27.3% vs 43% target) suggests potential differences in dataset characteristics, feature engineering approaches, or evaluation methodologies between current implementation and original research\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Feature Selection Insights**: L1 regularization with C=1 provides automatic feature selection capability, enabling identification of most predictive founding-time characteristics while eliminating noisy variables that could degrade model generalization performance\n",
    "- **Threshold Optimization Potential**: High AUC-ROC (78.1%) combined with precision recall imbalance indicates significant opportunity for prediction threshold tuning to achieve business-specific cost-sensitive optimization balancing investor risk tolerance and opportunity identification\n",
    "- **Baseline Model Establishment**: Results provide solid foundation for ensemble method comparison, with 70.9% recall representing upper bound for startup success detection while highlighting need for precision improvement through alternative algorithms\n",
    "- **Production Deployment Considerations**: Model demonstrates strong sensitivity for screening applications where missing potential successes carries higher cost than investigating false positives, suitable for initial filtering in venture capital deal flow management systems\n",
    "- **Cross-Validation Stability**: Best CV F1-score (26.7%) closely matches test performance (27.3%), indicating robust generalization without overfitting concerns and reliable performance estimation for production deployment scenarios\n",
    "- **Business Interpretation Framework**: Balanced class weighting with L1 regularization creates interpretable model where feature coefficients directly indicate founding time characteristics that increase/decrease acquisition probability, supporting stakeholder communication and investment decision justification processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea75ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1: Logistic Regression with Regularization\n",
      "Hyperparameter Grid:\n",
      "  C: [0.001, 0.01, 0.1, 1, 10, 100]\n",
      "  penalty: ['l1', 'l2']\n",
      "  solver: ['liblinear']\n",
      "  class_weight: [None, 'balanced']\n",
      "  max_iter: [1000]\n",
      "Running Grid Search Running Now\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Logistic Regression parameters:\n",
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Cross Validation F1-score: 0.267\n",
      "\n",
      "Logistic Regression Results:\n",
      "- Precision: 0.169 (Target: 0.570)\n",
      "- Recall: 0.709 (Target: 0.340)\n",
      "- F1-Score: 0.273 (Target: 0.430)\n",
      "- AUC-ROC: 0.781\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1: Logisitic Regression w/ regularization\n",
    "\n",
    "print(\"MODEL 1: Logistic Regression with Regularization\")\n",
    "\n",
    "# Hyperparameter grid for logistic regression\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],  # Works with L1 and L2\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in lr_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Grid search with cross validation\n",
    "print(\"Running Grid Search Now\")\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    lr_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',  # Optimize for F1 (balanced precision/recall)\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\")\n",
    "print(lr_grid.best_params_)\n",
    "print(f\"Best Cross Validation F1-score: {lr_grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluating the best model\n",
    "lr_best = lr_grid.best_estimator_\n",
    "lr_pred = lr_best.predict(X_test)\n",
    "lr_pred_proba = lr_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "lr_precision = precision_score(y_test, lr_pred)\n",
    "lr_recall = recall_score(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_proba)\n",
    "\n",
    "print(f\"\\nLogistic Regression Results:\")\n",
    "print(f\"- Precision: {lr_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {lr_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {lr_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {lr_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439845bb",
   "metadata": {},
   "source": [
    "## 4. MODEL 2: SVM (Support Vector Machine) with RBF (Radial Basis Function) Kernel\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Reduced Hyperparameter Grid Strategy**: Implemented computationally efficient parameter space exploration with focused ranges: regularization parameter C (0.5-5), RBF kernel gamma values (0.05-0.5), fixed RBF kernel selection, and balanced class weighting, totaling 16 hyperparameter combinations for faster training while maintaining comprehensive coverage\n",
    "- **Scaled Feature Preprocessing**: Applied StandardScaler transformation to training and test datasets ensuring zero mean unit variance normalization critical for SVM distance-based optimization, preventing feature scale bias that could dominate decision boundary formation in high dimensional startup characteristic space\n",
    "- **Probability Calibration Integration**: Enabled probability estimation through SVC probability=True parameter for AUC-ROC calculation compatibility, allowing comprehensive model evaluation across multiple metrics while maintaining SVM's discriminative classification capabilities\n",
    "- **Optimal Configuration Identification**: Selected best performing parameters through systematic grid search: C=1 (moderate regularization), gamma=0.1 (balanced kernel width), RBF kernel (non linear decision boundaries), and balanced class weighting, achieving 25.7% cross-validation F1-score across 80 total model fits\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Feature Scaling Necessity**: SVM algorithm sensitivity to feature magnitude differences requires standardization to prevent geographic density features (1-5 range) from being overshadowed by standardized founding year variables, ensuring equal contribution to decision boundary optimization and preventing algorithmic bias toward specific feature scales\n",
    "- **RBF Kernel Selection Justification**: Radial Basis Function kernel enables detection of non linear relationships between founding time characteristics and startup success probability, capturing complex interaction patterns (geographic-industry synergies, temporal-sector dependencies) that linear models cannot represent effectively\n",
    "- **Gamma Parameter Optimization Focus**: Gamma controls RBF kernel width determining decision boundary complexity, with optimal value (0.1) balancing model flexibility to capture startup success patterns against overfitting risk in 22-dimensional feature space with 7.72% positive class samples\n",
    "- **Computational Efficiency Strategy**: Reduced parameter grid (16 vs potential 100+ combinations) maintains thorough hyperparameter exploration while enabling practical training time on 28,860-sample dataset, balancing model optimization thoroughness with computational resource constraints\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Precision-Recall Tradeoff Consistency**: Achieved similar performance profile to Logistic Regression with moderate precision (15.5%) and strong recall (68.9%), indicating both algorithms identify similar startup success patterns but struggle with false positive control in severely imbalanced classification scenario\n",
    "- **Performance Gap vs Linear Model**: SVM F1-score (25.2%) trails Logistic Regression (27.3%) by 2.1 percentage points, suggesting linear decision boundaries may be sufficient for founding time feature relationships, questioning complexity benefit of non linear kernel approach for this specific prediction task\n",
    "- **Academic Benchmark Underperformance**: Results fall significantly short of published targets (F1: 25.2% vs 43% target, precision: 15.5% vs 57% target), indicating either dataset differences, feature engineering variations, or need for advanced ensemble methods to achieve competitive performance levels\n",
    "- **AUC-ROC Discriminative Assessment**: Moderate AUC-ROC performance (74.0%) demonstrates reasonable ranking ability but 4.1 percentage point decline vs Logistic Regression (78.1%) suggests RBF kernel complexity may introduce noise rather than capturing meaningful non linear patterns in startup success prediction\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Algorithm Comparison Baseline**: SVM results provide critical comparison point validating that linear relationships dominate founding-time startup characteristics, informing ensemble strategy to emphasize linear models over complex non-linear approaches for optimal performance balance\n",
    "- **Feature Engineering Validation**: Similar precision recall patterns across linear and non-linear models confirm feature set captures primary startup success signals effectively, indicating preprocessing pipeline success while highlighting need for advanced sampling techniques rather than feature complexity increases\n",
    "- **Computational Resource Assessment**: Reduced training time through focused hyperparameter grid demonstrates practical deployment considerations for real time prediction systems, where SVM computational overhead may not justify marginal performance improvements over efficient linear alternatives\n",
    "- **Class Imbalance Handling Effectiveness**: Balanced class weighting produces consistent recall performance (68.9%) across algorithm types, validating imbalanced classification strategy while emphasizing need for precision improvement through threshold optimization or ensemble resampling techniques\n",
    "- **Production Deployment Considerations**: SVM model provides reliable backup algorithm with different algorithmic assumptions, enabling ensemble diversity and robustness against edge cases where linear assumptions fail, while scaled feature requirements ensure consistent preprocessing pipeline across deployment scenarios\n",
    "- **Model Interpretability Limitations**: RBF kernel decision boundaries lack direct feature coefficient interpretation compared to L1 regularized Logistic Regression, reducing stakeholder communication effectiveness and limiting business insight generation for venture capital investment decision support frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8147fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced Hyperparameter Grid (faster training):\n",
      "  C: [0.5, 1, 2, 5]\n",
      "  gamma: [0.05, 0.1, 0.2, 0.5]\n",
      "  kernel: ['rbf']\n",
      "  class_weight: ['balanced']\n",
      "\n",
      "Running Grid Search on scaled features...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best SVM parameters:\n",
      "{'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best CV F1-score: 0.257\n",
      "\n",
      "SVM Results:\n",
      "- Precision: 0.155 (Target: 0.570)\n",
      "- Recall: 0.689 (Target: 0.340)\n",
      "- F1-Score: 0.252 (Target: 0.430)\n",
      "- AUC-ROC: 0.740\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: SVM w/ RBF Kernel\n",
    "\n",
    "print(\"MODEL 2: SVM w/ RBF Kernel\")\n",
    "\n",
    "# Hyperparameter grid for SVM (using scaled features)\n",
    "svm_param_grid = {\n",
    "    'C': [0.5, 1, 2, 5],\n",
    "    'gamma': [0.05, 0.1, 0.2, 0.5],\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "print(\"Reduced Hyperparameter Grid (faster training):\")\n",
    "for param, values in svm_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Grid search with cross validation (using scaled data)\n",
    "print(\"\\nRunning Grid Search on scaled features...\")\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),  # Enable probability for AUC\n",
    "    svm_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best SVM parameters:\")\n",
    "print(svm_grid.best_params_)\n",
    "print(f\"Best CV F1-score: {svm_grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluating the best model\n",
    "svm_best = svm_grid.best_estimator_\n",
    "svm_pred = svm_best.predict(X_test_scaled)\n",
    "svm_pred_proba = svm_best.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "svm_precision = precision_score(y_test, svm_pred)\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_proba)\n",
    "\n",
    "print(f\"\\nSVM Results:\")\n",
    "print(f\"- Precision: {svm_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {svm_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {svm_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {svm_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb15783",
   "metadata": {},
   "source": [
    "## 5. MODEL 3: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5951cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3: XGBoost\n",
      "Hyperparameter Grid:\n",
      "  n_estimators: [100, 200, 300]\n",
      "  max_depth: [3, 4, 5]\n",
      "  learning_rate: [0.01, 0.1]\n",
      "  subsample: [0.8, 0.9, 1.0]\n",
      "  colsample_bytree: [0.8, 0.9, 1.0]\n",
      "  scale_pos_weight: [1, 5, 10]\n",
      "\n",
      "Running Randomized Search...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best XGBoost parameters:\n",
      "{'subsample': 0.8, 'scale_pos_weight': 5, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "Best CV F1-score: 0.297\n",
      "\n",
      "XGBoost Results:\n",
      "- Precision: 0.234 (Target: 0.570)\n",
      "- Recall: 0.388 (Target: 0.340)\n",
      "- F1-Score: 0.291 (Target: 0.430)\n",
      "- AUC-ROC: 0.790\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: XGBoost (Academic Paper Best Preforming Model)\n",
    "\n",
    "print(\"MODEL 3: XGBoost\")\n",
    "\n",
    "# Hyperparamter Grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'scale_pos_weight': [1, 5, 10]  # Handles class imbalance (12:1 ratio)\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in xgb_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Randomized search (more efficient than grid search for XGBoost)\n",
    "print(\"\\nRunning Randomized Search...\")\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    ),\n",
    "    xgb_param_grid,\n",
    "    n_iter=50,  # 50 random combinations\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost parameters:\")\n",
    "print(xgb_random.best_params_)\n",
    "print(f\"Best CV F1-score: {xgb_random.best_score_:.3f}\")\n",
    "\n",
    "# Evaluates best model\n",
    "xgb_best = xgb_random.best_estimator_\n",
    "xgb_pred = xgb_best.predict(X_test)\n",
    "xgb_pred_proba = xgb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "xgb_precision = precision_score(y_test, xgb_pred)\n",
    "xgb_recall = recall_score(y_test, xgb_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_pred)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"- Precision: {xgb_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {xgb_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {xgb_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {xgb_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
