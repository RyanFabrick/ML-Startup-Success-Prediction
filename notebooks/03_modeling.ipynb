{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d071870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for Modeling\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import os\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import (\n",
    "    cross_val_score, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, precision_recall_curve,\n",
    "    roc_auc_score, roc_curve, precision_score, recall_score, f1_score\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import xgboost as xgb\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c09ad4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter Warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4f2bda",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data\n",
    "\n",
    "### Loading Logic\n",
    "\n",
    "- Stratified splits for academic replication\n",
    "- Scaled versions for SVM algorithms\n",
    "- Proper Series conversion for target variables\n",
    "\n",
    "### Data Integrity\n",
    "\n",
    "- Training: 28,860 samples × 22 features\n",
    "- Test: 7,215 samples × 22 features\n",
    "- Balanced success rates (7.72% both splits)\n",
    "- Feature categories sum correctly (3 + 15 + 4 = 22)\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- This follows the academic replication strategy from previous preprocessing and feature engineering notebook, using stratified splits to match Żbikowski & Antosiuk (2021) methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72524ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Data for Academic Paper Replication Modeling\n",
      "Loading processed data first\n",
      "Loading sclaed versions for SVM second\n",
      "Training set: 28,860 samples, 22 features\n",
      "Test set: 7,215 samples, 22 features\n",
      "Training success rate: 7.72%\n",
      "Test success rate: 7.72%\n",
      "\n",
      "Feature breakdown:\n",
      "- Geographic features: 3\n",
      "- Industry features: 15\n",
      "- Temporal features: 4\n",
      "- Total features: 22\n"
     ]
    }
   ],
   "source": [
    "# Loading Data for Academic Paper Replication Modeling\n",
    "\n",
    "print(\"Loading Data for Academic Paper Replication Modeling\")\n",
    "\n",
    "# Loads the stratified splits (academic paper replication)\n",
    "print(\"Loading processed data first\")\n",
    "X_train = pd.read_csv('../data/processed/X_train_stratified.csv')\n",
    "X_test = pd.read_csv('../data/processed/X_test_stratified.csv')\n",
    "y_train = pd.read_csv('../data/processed/y_train_stratified.csv').iloc[:, 0]  # Convert to Series\n",
    "y_test = pd.read_csv('../data/processed/y_test_stratified.csv').iloc[:, 0]    # Convert to Series\n",
    "\n",
    "# Loads scaled versions for SVM\n",
    "print(\"Loading sclaed versions for SVM second\")\n",
    "X_train_scaled = pd.read_csv('../data/processed/X_train_scaled.csv')\n",
    "X_test_scaled = pd.read_csv('../data/processed/X_test_scaled.csv')\n",
    "\n",
    "print(f\"Training set: {X_train.shape[0]:,} samples, {X_train.shape[1]} features\")\n",
    "print(f\"Test set: {X_test.shape[0]:,} samples, {X_test.shape[1]} features\")\n",
    "print(f\"Training success rate: {y_train.mean()*100:.2f}%\")\n",
    "print(f\"Test success rate: {y_test.mean()*100:.2f}%\")\n",
    "\n",
    "# Feature categories for analysis\n",
    "geographic_features = ['region_startup_density', 'city_startup_density', 'is_usa']\n",
    "industry_features = [col for col in X_train.columns if col.startswith('category_')]\n",
    "temporal_features = ['founded_year_std', 'era_dotcom_era', 'era_post_crash', 'era_recovery']\n",
    "\n",
    "print(f\"\\nFeature breakdown:\")\n",
    "print(f\"- Geographic features: {len(geographic_features)}\")\n",
    "print(f\"- Industry features: {len(industry_features)}\")\n",
    "print(f\"- Temporal features: {len(temporal_features)}\")\n",
    "print(f\"- Total features: {len(geographic_features) + len(industry_features) + len(temporal_features)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be90ec65",
   "metadata": {},
   "source": [
    "## 2. Baseline Model Setup\n",
    "\n",
    "### Cross Validation Strategy\n",
    "\n",
    "- 5 fold stratified CV is a proper choice for imbalanced dataset (7.72% success rate)\n",
    "- shuffle=True with random_state=42 ensures reproducible results\n",
    "- Stratification maintains class balance across all folds\n",
    "\n",
    "### Evaluation Metrics\n",
    "\n",
    "- Proper choices for imbalanced classification: precision, recall, f1, roc_auc\n",
    "- Matches academic paper's (Żbikowski & Antosiuk (2021)) evaluation framework\n",
    "- Avoids accuracy (it would be misleading with 92.28% negative class)\n",
    "\n",
    "### Academic Benchmarks\n",
    "\n",
    "- Are correctly extracted from Żbikowski & Antosiuk (2021)\n",
    "- Clear performance targets for validation\n",
    "- F1-score of 43% reflects the precision/recall balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48c32f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model Setup\n",
      "Cross-validation: 5-fold stratified\n",
      "Evaluation metrics: ['precision', 'recall', 'f1', 'roc_auc']\n",
      "\n",
      "Academic targets to match/exceed:\n",
      "- Precision: 57%\n",
      "- Recall: 34%\n",
      "- F1-Score: 43%\n"
     ]
    }
   ],
   "source": [
    "# Baseline Model Setup/Configuration\n",
    "\n",
    "print(\"Baseline Model Setup\")\n",
    "\n",
    "# Sets up cross validation strategy\n",
    "cv_strategy = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(\"Cross-validation: 5-fold stratified\")\n",
    "\n",
    "# Defines scoring metrics (academic paper replication metrics)\n",
    "scoring_metrics = ['precision', 'recall', 'f1', 'roc_auc']\n",
    "print(f\"Evaluation metrics: {scoring_metrics}\")\n",
    "\n",
    "# Academic targets from academic paper: Żbikowski & Antosiuk (2021)\n",
    "TARGET_PRECISION = 0.57\n",
    "TARGET_RECALL = 0.34\n",
    "TARGET_F1 = 0.43\n",
    "\n",
    "print(f\"\\nAcademic targets to match/exceed:\")\n",
    "print(f\"- Precision: {TARGET_PRECISION:.0%}\")\n",
    "print(f\"- Recall: {TARGET_RECALL:.0%}\")\n",
    "print(f\"- F1-Score: {TARGET_F1:.0%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f43eeb0",
   "metadata": {},
   "source": [
    "## 3. MODEL 1: Logistic Regression (With Regularization)\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Hyperparameter Grid Implementation**: Designed systematic parameter space exploration covering regularization strength (C: 0.001-100), penalty types (L1/L2), class weighting strategies (None/balanced), and solver configuration (liblinear) to identify optimal model configuration for imbalanced startup classification task\n",
    "- **Grid Search Cross-Validation Execution**: Applied 5 fold stratified cross validation across 24 hyperparameter combinations (120 total model fits), optimizing for F1-score to balance precision-recall tradeoffs critical for startup success prediction where both false positives and false negatives carry significant business costs\n",
    "- **Optimal Configuration Selection**: Identified best performing parameters through systematic evaluation: C=1 (moderate regularization), L1 penalty (feature selection capability), balanced class weighting (addressing 7.72% positive class imbalance), and liblinear solver (efficient for L1/L2 penalties)\n",
    "- **Model Evaluation Pipeline**: Executed comprehensive performance assessment using test set predictions, calculating precision (16.9%), recall (70.9%), F1-score (27.3%), and AUC-ROC (78.1%) metrics against academic benchmarks from Żbikowski & Antosiuk (2021) research\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Academic Replication Compliance**: Applied identical evaluation framework to published research methodology, enabling direct performance comparison with established benchmarks (57% precision, 34% recall, 43% F1-score) while maintaining consistent cross validation and scoring approaches\n",
    "- **Imbalanced Classification Optimization**: Implemented balanced class weighting to address severe class imbalance (92.28% negative class), preventing model bias toward majority class predictions that would achieve high accuracy but fail to identify startup success patterns\n",
    "- **Regularization Strategy Selection**: L1 penalty selection enables automatic feature selection during training, identifying most predictive features among 22 founding time variables while preventing overfitting in high dimensional feature space relative to positive class sample size\n",
    "- **F1-Score Optimization Focus**: Targeted F1-score maximization during hyperparameter tuning to achieve optimal precision recall balance, reflecting real world venture capital decision-making where both missed opportunities (false negatives) and wasted due diligence (false positives) impose significant costs\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Recall Excellence vs Precision Challenge**: Achieved exceptional recall performance (70.9%) exceeding academic target by 2.1x, successfully identifying 71% of actual startup successes, but suffered from low precision (16.9%) indicating high false positive rate with only 17% of positive predictions being correct\n",
    "- **Class Imbalance Impact**: Balanced class weighting strategy effectively addressed minority class detection but created precision recall tradeoff where model sensitivity improvement came at cost of prediction specificity, resulting in 83% false positive rate among predicted successes\n",
    "- **Discriminative Capability Validation**: Strong AUC-ROC performance (78.1%) demonstrates robust ranking ability to distinguish successful from unsuccessful startups, indicating feature set contains meaningful predictive signals despite precision challenges\n",
    "- **Academic Benchmark Comparison**: Performance gap relative to published targets (F1: 27.3% vs 43% target) suggests potential differences in dataset characteristics, feature engineering approaches, or evaluation methodologies between current implementation and original research\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Feature Selection Insights**: L1 regularization with C=1 provides automatic feature selection capability, enabling identification of most predictive founding-time characteristics while eliminating noisy variables that could degrade model generalization performance\n",
    "- **Threshold Optimization Potential**: High AUC-ROC (78.1%) combined with precision recall imbalance indicates significant opportunity for prediction threshold tuning to achieve business-specific cost-sensitive optimization balancing investor risk tolerance and opportunity identification\n",
    "- **Baseline Model Establishment**: Results provide solid foundation for ensemble method comparison, with 70.9% recall representing upper bound for startup success detection while highlighting need for precision improvement through alternative algorithms\n",
    "- **Production Deployment Considerations**: Model demonstrates strong sensitivity for screening applications where missing potential successes carries higher cost than investigating false positives, suitable for initial filtering in venture capital deal flow management systems\n",
    "- **Cross-Validation Stability**: Best CV F1-score (26.7%) closely matches test performance (27.3%), indicating robust generalization without overfitting concerns and reliable performance estimation for production deployment scenarios\n",
    "- **Business Interpretation Framework**: Balanced class weighting with L1 regularization creates interpretable model where feature coefficients directly indicate founding time characteristics that increase/decrease acquisition probability, supporting stakeholder communication and investment decision justification processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ea75ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1: Logistic Regression with Regularization\n",
      "Hyperparameter Grid:\n",
      "  C: [0.001, 0.01, 0.1, 1, 10, 100]\n",
      "  penalty: ['l1', 'l2']\n",
      "  solver: ['liblinear']\n",
      "  class_weight: [None, 'balanced']\n",
      "  max_iter: [1000]\n",
      "Running Grid Search Now\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Logistic Regression parameters:\n",
      "{'C': 1, 'class_weight': 'balanced', 'max_iter': 1000, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Best Cross Validation F1-score: 0.267\n",
      "\n",
      "Logistic Regression Results:\n",
      "- Precision: 0.169 (Target: 0.570)\n",
      "- Recall: 0.709 (Target: 0.340)\n",
      "- F1-Score: 0.273 (Target: 0.430)\n",
      "- AUC-ROC: 0.781\n"
     ]
    }
   ],
   "source": [
    "# MODEL 1: Logisitic Regression w/ regularization\n",
    "\n",
    "print(\"MODEL 1: Logistic Regression with Regularization\")\n",
    "\n",
    "# Hyperparameter grid for logistic regression\n",
    "lr_param_grid = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'solver': ['liblinear'],  # Works with L1 and L2\n",
    "    'class_weight': [None, 'balanced'],\n",
    "    'max_iter': [1000]\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in lr_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Grid search with cross validation\n",
    "print(\"Running Grid Search Now\")\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42),\n",
    "    lr_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',  # Optimize for F1 (balanced precision/recall)\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "lr_grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Logistic Regression parameters:\")\n",
    "print(lr_grid.best_params_)\n",
    "print(f\"Best Cross Validation F1-score: {lr_grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluating the best model\n",
    "lr_best = lr_grid.best_estimator_\n",
    "lr_pred = lr_best.predict(X_test)\n",
    "lr_pred_proba = lr_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "lr_precision = precision_score(y_test, lr_pred)\n",
    "lr_recall = recall_score(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "lr_auc = roc_auc_score(y_test, lr_pred_proba)\n",
    "\n",
    "print(f\"\\nLogistic Regression Results:\")\n",
    "print(f\"- Precision: {lr_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {lr_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {lr_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {lr_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439845bb",
   "metadata": {},
   "source": [
    "## 4. MODEL 2: SVM (Support Vector Machine) with RBF (Radial Basis Function) Kernel\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Reduced Hyperparameter Grid Strategy**: Implemented computationally efficient parameter space exploration with focused ranges: regularization parameter C (0.5-5), RBF kernel gamma values (0.05-0.5), fixed RBF kernel selection, and balanced class weighting, totaling 16 hyperparameter combinations for faster training while maintaining comprehensive coverage\n",
    "- **Scaled Feature Preprocessing**: Applied StandardScaler transformation to training and test datasets ensuring zero mean unit variance normalization critical for SVM distance-based optimization, preventing feature scale bias that could dominate decision boundary formation in high dimensional startup characteristic space\n",
    "- **Probability Calibration Integration**: Enabled probability estimation through SVC probability=True parameter for AUC-ROC calculation compatibility, allowing comprehensive model evaluation across multiple metrics while maintaining SVM's discriminative classification capabilities\n",
    "- **Optimal Configuration Identification**: Selected best performing parameters through systematic grid search: C=1 (moderate regularization), gamma=0.1 (balanced kernel width), RBF kernel (non linear decision boundaries), and balanced class weighting, achieving 25.7% cross-validation F1-score across 80 total model fits\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Feature Scaling Necessity**: SVM algorithm sensitivity to feature magnitude differences requires standardization to prevent geographic density features (1-5 range) from being overshadowed by standardized founding year variables, ensuring equal contribution to decision boundary optimization and preventing algorithmic bias toward specific feature scales\n",
    "- **RBF Kernel Selection Justification**: Radial Basis Function kernel enables detection of non linear relationships between founding time characteristics and startup success probability, capturing complex interaction patterns (geographic-industry synergies, temporal-sector dependencies) that linear models cannot represent effectively\n",
    "- **Gamma Parameter Optimization Focus**: Gamma controls RBF kernel width determining decision boundary complexity, with optimal value (0.1) balancing model flexibility to capture startup success patterns against overfitting risk in 22-dimensional feature space with 7.72% positive class samples\n",
    "- **Computational Efficiency Strategy**: Reduced parameter grid (16 vs potential 100+ combinations) maintains thorough hyperparameter exploration while enabling practical training time on 28,860-sample dataset, balancing model optimization thoroughness with computational resource constraints\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Precision-Recall Tradeoff Consistency**: Achieved similar performance profile to Logistic Regression with moderate precision (15.5%) and strong recall (68.9%), indicating both algorithms identify similar startup success patterns but struggle with false positive control in severely imbalanced classification scenario\n",
    "- **Performance Gap vs Linear Model**: SVM F1-score (25.2%) trails Logistic Regression (27.3%) by 2.1 percentage points, suggesting linear decision boundaries may be sufficient for founding time feature relationships, questioning complexity benefit of non linear kernel approach for this specific prediction task\n",
    "- **Academic Benchmark Underperformance**: Results fall significantly short of published targets (F1: 25.2% vs 43% target, precision: 15.5% vs 57% target), indicating either dataset differences, feature engineering variations, or need for advanced ensemble methods to achieve competitive performance levels\n",
    "- **AUC-ROC Discriminative Assessment**: Moderate AUC-ROC performance (74.0%) demonstrates reasonable ranking ability but 4.1 percentage point decline vs Logistic Regression (78.1%) suggests RBF kernel complexity may introduce noise rather than capturing meaningful non linear patterns in startup success prediction\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Algorithm Comparison Baseline**: SVM results provide critical comparison point validating that linear relationships dominate founding-time startup characteristics, informing ensemble strategy to emphasize linear models over complex non-linear approaches for optimal performance balance\n",
    "- **Feature Engineering Validation**: Similar precision recall patterns across linear and non-linear models confirm feature set captures primary startup success signals effectively, indicating preprocessing pipeline success while highlighting need for advanced sampling techniques rather than feature complexity increases\n",
    "- **Computational Resource Assessment**: Reduced training time through focused hyperparameter grid demonstrates practical deployment considerations for real time prediction systems, where SVM computational overhead may not justify marginal performance improvements over efficient linear alternatives\n",
    "- **Class Imbalance Handling Effectiveness**: Balanced class weighting produces consistent recall performance (68.9%) across algorithm types, validating imbalanced classification strategy while emphasizing need for precision improvement through threshold optimization or ensemble resampling techniques\n",
    "- **Production Deployment Considerations**: SVM model provides reliable backup algorithm with different algorithmic assumptions, enabling ensemble diversity and robustness against edge cases where linear assumptions fail, while scaled feature requirements ensure consistent preprocessing pipeline across deployment scenarios\n",
    "- **Model Interpretability Limitations**: RBF kernel decision boundaries lack direct feature coefficient interpretation compared to L1 regularized Logistic Regression, reducing stakeholder communication effectiveness and limiting business insight generation for venture capital investment decision support frameworks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8147fd14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 2: SVM w/ RBF Kernel\n",
      "Reduced Hyperparameter Grid (faster training):\n",
      "  C: [0.5, 1, 2, 5]\n",
      "  gamma: [0.05, 0.1, 0.2, 0.5]\n",
      "  kernel: ['rbf']\n",
      "  class_weight: ['balanced']\n",
      "\n",
      "Running Grid Search on scaled features...\n",
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "Best SVM parameters:\n",
      "{'C': 1, 'class_weight': 'balanced', 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best CV F1-score: 0.257\n",
      "\n",
      "SVM Results:\n",
      "- Precision: 0.155 (Target: 0.570)\n",
      "- Recall: 0.689 (Target: 0.340)\n",
      "- F1-Score: 0.252 (Target: 0.430)\n",
      "- AUC-ROC: 0.740\n"
     ]
    }
   ],
   "source": [
    "# MODEL 2: SVM w/ RBF Kernel\n",
    "\n",
    "print(\"MODEL 2: SVM w/ RBF Kernel\")\n",
    "\n",
    "# Hyperparameter grid for SVM (using scaled features)\n",
    "svm_param_grid = {\n",
    "    'C': [0.5, 1, 2, 5],\n",
    "    'gamma': [0.05, 0.1, 0.2, 0.5],\n",
    "    'kernel': ['rbf'],\n",
    "    'class_weight': ['balanced']\n",
    "}\n",
    "\n",
    "print(\"Reduced Hyperparameter Grid (faster training):\")\n",
    "for param, values in svm_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Grid search with cross validation (using scaled data)\n",
    "print(\"\\nRunning Grid Search on scaled features...\")\n",
    "svm_grid = GridSearchCV(\n",
    "    SVC(probability=True, random_state=42),  # Enable probability for AUC\n",
    "    svm_param_grid,\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "svm_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"Best SVM parameters:\")\n",
    "print(svm_grid.best_params_)\n",
    "print(f\"Best CV F1-score: {svm_grid.best_score_:.3f}\")\n",
    "\n",
    "# Evaluating the best model\n",
    "svm_best = svm_grid.best_estimator_\n",
    "svm_pred = svm_best.predict(X_test_scaled)\n",
    "svm_pred_proba = svm_best.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "svm_precision = precision_score(y_test, svm_pred)\n",
    "svm_recall = recall_score(y_test, svm_pred)\n",
    "svm_f1 = f1_score(y_test, svm_pred)\n",
    "svm_auc = roc_auc_score(y_test, svm_pred_proba)\n",
    "\n",
    "print(f\"\\nSVM Results:\")\n",
    "print(f\"- Precision: {svm_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {svm_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {svm_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {svm_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb15783",
   "metadata": {},
   "source": [
    "## 5. MODEL 3: XGBoost\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Hyperparameter Grid Implementation**: Designed parameter space exploration covering ensemble configuration (n_estimators: 100-300), tree complexity (max_depth: 3-5), learning dynamics (learning_rate: 0.01-0.1), regularization strategies (subsample: 0.8-1.0, colsample_bytree: 0.8-1.0), and class imbalance handling (scale_pos_weight: 1-10) to identify optimal XGBoost configuration for imbalanced startup classification task\n",
    "- **Randomized Search Cross-Validation Execution**: Applied efficient randomized search across 50 parameter combinations (250 total model fits) using 5 fold stratified crossvvalidation, optimizing for F1-score to balance precision-recall tradeoffs while reducing computational overhead compared to exhaustive grid search approach for high dimensional hyperparameter space\n",
    "- **Optimal Configuration Selection**: Identified best performing parameters through systematic evaluation: subsample=0.8 (regularization through row sampling), scale_pos_weight=5 (moderate class imbalance compensation), n_estimators=100 (ensemble size), max_depth=3 (controlled tree complexity), learning_rate=0.1 (balanced learning speed), colsample_bytree=0.8 (feature sampling regularization)\n",
    "- **Model Evaluation Pipeline**: Executed comprehensive performance assessment using test set predictions, calculating precision (23.4%), recall (38.8%), F1-score (29.1%), and AUC-ROC (79.0%) metrics against academic benchmarks from Żbikowski & Antosiuk (2021) research\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Academic Replication Excellence**: XGBoost represents the best performing algorithm from original research, enabling direct validation of gradient boosting effectiveness for startup success prediction while maintaining identical evaluation framework and bias free methodology for fair benchmark comparison\n",
    "- **Ensemble Learning Optimization**: Gradient boosting architecture addresses imbalanced classification challenges through sequential weak learner improvement, iterative residual correction, and adaptive sample weighting that naturally handles minority class detection better than single-model approaches\n",
    "- **Class Imbalance Strategy Integration**: scale_pos_weight=5 provides targeted class imbalance handling by increasing penalty for false negatives on minority class (successful startups), balancing the 12:1 class ratio without requiring external resampling techniques that could introduce data artifacts\n",
    "- **Regularization Framework Deployment**: Combined row sampling (subsample=0.8) and feature sampling (colsample_bytree=0.8) prevents overfitting while maintaining predictive power, particularly important for founding-time feature constraints where data richness is limited compared to post-founding information\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Balanced Performance Achievement**: Achieved superior F1-score balance (29.1%) compared to previous models through optimal precision recall tradeoff, with precision (23.4%) showing significant improvement over Logistic Regression (16.9%) while maintaining competitive recall (38.8%) for comprehensive startup success detection\n",
    "- **Academic Benchmark Convergence**: F1-score (29.1%) approaches published target (43.0%) more closely than linear models, representing 67.7% of academic benchmark achievement while demonstrating ensemble method superiority for complex startup ecosystem pattern recognition\n",
    "- **Recall Optimization Excellence**: Recall performance (38.8%) exceeds academic target (34.0%) by 14.1%, successfully identifying 39% of actual startup successes while maintaining more controlled false positive rate compared to previous high recall models\n",
    "- **Discriminative Capability Leadership**: Strongest AUC-ROC performance (79.0%) among all models demonstrates superior ranking ability to distinguish successful from unsuccessful startups, indicating gradient boosting effectively captures non-linear relationships in founding time feature interactions\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Feature Interaction Discovery**: XGBoost's tree based architecture automatically detects complex feature interactions (geographic-industry synergies, temporal sector patterns) that linear models cannot capture, enabling discovery of previously unknown predictive patterns in startup ecosystem data\n",
    "- **Regularization Effectiveness Validation**: Optimal hyperparameters (subsample=0.8, colsample_bytree=0.8) demonstrate that regularization is critical for founding time feature constraints, preventing overfitting while maintaining predictive signal strength in limited information environment\n",
    "- **Class Imbalance Handling Superiority**: scale_pos_weight=5 provides more nuanced class imbalance treatment than binary balanced approaches, achieving optimal minority class detection without excessive false positive generation that could undermine practical deployment effectiveness\n",
    "- **Ensemble Model Foundation**: Results establish XGBoost as strongest individual model, providing foundation for meta learning approaches where XGBoost predictions could serve as key features in stacked ensemble architectures for further performance improvement\n",
    "- **Cross-Validation Stability Excellence**: Best CV F1-score (29.7%) closely matches test performance (29.1%), indicating robust generalization without overfitting concerns and reliable performance estimation for production deployment scenarios across different data partitions\n",
    "- **Business Decision Support Enhancement**: Superior precision-recall balance makes XGBoost most suitable for practical venture capital applications where both missed opportunities (false negatives) and wasted due diligence (false positives) carry significant costs, supporting risk balanced investment screening processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5951cae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 3: XGBoost\n",
      "Hyperparameter Grid:\n",
      "  n_estimators: [100, 200, 300]\n",
      "  max_depth: [3, 4, 5]\n",
      "  learning_rate: [0.01, 0.1]\n",
      "  subsample: [0.8, 0.9, 1.0]\n",
      "  colsample_bytree: [0.8, 0.9, 1.0]\n",
      "  scale_pos_weight: [1, 5, 10]\n",
      "\n",
      "Running Randomized Search...\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Best XGBoost parameters:\n",
      "{'subsample': 0.8, 'scale_pos_weight': 5, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1, 'colsample_bytree': 0.8}\n",
      "Best CV F1-score: 0.297\n",
      "\n",
      "XGBoost Results:\n",
      "- Precision: 0.234 (Target: 0.570)\n",
      "- Recall: 0.388 (Target: 0.340)\n",
      "- F1-Score: 0.291 (Target: 0.430)\n",
      "- AUC-ROC: 0.790\n"
     ]
    }
   ],
   "source": [
    "# MODEL 3: XGBoost (Academic Paper Best Preforming Model)\n",
    "\n",
    "print(\"MODEL 3: XGBoost\")\n",
    "\n",
    "# Hyperparamter Grid for XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'scale_pos_weight': [1, 5, 10]  # Handles class imbalance (12:1 ratio)\n",
    "}\n",
    "\n",
    "print(\"Hyperparameter Grid:\")\n",
    "for param, values in xgb_param_grid.items():\n",
    "    print(f\"  {param}: {values}\")\n",
    "\n",
    "# Randomized search (more efficient than grid search for XGBoost)\n",
    "print(\"\\nRunning Randomized Search...\")\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    xgb.XGBClassifier(\n",
    "        random_state=42,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    ),\n",
    "    xgb_param_grid,\n",
    "    n_iter=50,  # 50 random combinations\n",
    "    cv=cv_strategy,\n",
    "    scoring='f1',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_random.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best XGBoost parameters:\")\n",
    "print(xgb_random.best_params_)\n",
    "print(f\"Best CV F1-score: {xgb_random.best_score_:.3f}\")\n",
    "\n",
    "# Evaluates best model\n",
    "xgb_best = xgb_random.best_estimator_\n",
    "xgb_pred = xgb_best.predict(X_test)\n",
    "xgb_pred_proba = xgb_best.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Calculates the metrics\n",
    "xgb_precision = precision_score(y_test, xgb_pred)\n",
    "xgb_recall = recall_score(y_test, xgb_pred)\n",
    "xgb_f1 = f1_score(y_test, xgb_pred)\n",
    "xgb_auc = roc_auc_score(y_test, xgb_pred_proba)\n",
    "\n",
    "print(f\"\\nXGBoost Results:\")\n",
    "print(f\"- Precision: {xgb_precision:.3f} (Target: {TARGET_PRECISION:.3f})\")\n",
    "print(f\"- Recall: {xgb_recall:.3f} (Target: {TARGET_RECALL:.3f})\")\n",
    "print(f\"- F1-Score: {xgb_f1:.3f} (Target: {TARGET_F1:.3f})\")\n",
    "print(f\"- AUC-ROC: {xgb_auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc8ce9",
   "metadata": {},
   "source": [
    "## 6. Model Comparison and Academic Validation\n",
    "\n",
    "### Performance Summary\n",
    "\n",
    "This evaluation of three machine learning algorithms/models reveals distinct performance patterns when predicting startup success using founding time features only\n",
    "\n",
    "### Results Table\n",
    "\n",
    "| Model | Precision | Recall | F1-Score | AUC-ROC |\n",
    "|-------|-----------|--------|----------|---------|\n",
    "| **Logistic Regression** | 0.169 | 0.709 | 0.273 | 0.781 |\n",
    "| **SVM (RBF)** | 0.155 | 0.689 | 0.252 | 0.740 |\n",
    "| **XGBoost** | 0.234 | 0.388 | 0.291 | 0.790 |\n",
    "| **Academic Target** | 0.570 | 0.340 | 0.430 | NA |\n",
    "\n",
    "### Best Performing Model\n",
    "\n",
    "**XGBoost** with F1-Score of **0.291**, Precision of 0.234, Recall of 0.388, and AUC-ROC of 0.790\n",
    "\n",
    "## 5.2 Academic Validation Analysis\n",
    "\n",
    "### 5.2.1 Benchmark Comparison\n",
    "\n",
    "Our models were evaluated against the academic targets from Żbikowski & Antosiuk (2021):\n",
    "- Target Precision: **57.0%**\n",
    "- Target Recall: **34.0%**\n",
    "- Target F1-Score: **43.0%**\n",
    "\n",
    "### Performance Gap Analysis\n",
    "\n",
    "- **Critical Finding**: No models met or exceeded the academic F1 target of 43.0%\n",
    "- **Precision Gap**: All models underperformed (16.9% vs 57.0% target)\n",
    "- **Recall Advantage**: Linear models (Logistic Regression, SVM) exceeded recall targets by 2x\n",
    "- **F1-Score Gap**: Best model (XGBoost) achieved 67.7% of academic benchmark\n",
    "\n",
    "### Model Specific Analysis\n",
    "\n",
    "**Logistic Regression**\n",
    "- **Strengths**: Highest recall (70.9%), excellent minority class detection\n",
    "- **Weaknesses**: Lowest precision (16.9%), high false positive rate\n",
    "- **Pattern**: High sensitivity, low specificity\n",
    "\n",
    "**SVM (RBF Kernel)**\n",
    "- **Strengths**: Consistent with linear model patterns\n",
    "- **Weaknesses**: Lowest overall performance across all metrics\n",
    "- **Insight**: RBF complexity didn't improve upon linear relationships\n",
    "\n",
    "**XGBoost**\n",
    "- **Strengths**: Best precision recall balance, highest F1-score and AUC-ROC\n",
    "- **Advantages**: Superior feature interaction detection, optimal regularization\n",
    "- **Business Value**: Most suitable for practical deployment if part of overall goal/mission\n",
    "\n",
    "### Methodological Insights\n",
    "\n",
    "\n",
    "- The consistent underperformance across all models suggests that **founding time features alone** may be insufficient for achieving academic benchmark performance, indicating:\n",
    "    - **Information Constraint**: Limited predictive signal from incorporation time data\n",
    "    - **Dataset Differences**: Potential variations in data quality or preprocessing approaches\n",
    "    - **Temporal Effects**: Different economic conditions between studies\n",
    "    \n",
    "- The precision recall tradeoff pattern across all models reflects the challenge of **severe class imbalance** (7.72% success rate):\n",
    "    - High recall models identify most successes but generate many false positives\n",
    "    - Balanced approaches (XGBoost) provide better practical deployment characteristics\n",
    "    - All models demonstrate reasonable discriminative ability (AUC-ROC 74-79%)\n",
    "    \n",
    "- **Linear relationships** could possibly dominate founding time features, as evidenced by:\n",
    "    - SVM RBF underperforming compared to linear approaches\n",
    "    - XGBoost's tree-based ensemble providing marginal improvement\n",
    "    - Similar recall patterns across different algorithmic assumptions\n",
    "\n",
    "### Academic Validation Conclusion\n",
    "\n",
    "- While none of the models achieved the academic performance targets, this outcome provides valuable insights:\n",
    "    - **Methodological Validation**: Confirms the difficulty of bias-free startup success prediction\n",
    "    - **Dataset Authenticity**: Results align with realistic startup ecosystem challenges\n",
    "    - **Practical Value**: Models still provide meaningful screening and ranking capabilities\n",
    "    - **Research Gap**: Identifies opportunities for advanced ensemble methods and feature engineering\n",
    "- The 67.7% achievement of academic F1-score benchmark by XGBoost represents a solid foundation for further model development and demonstrates the viability of founding time feature approaches for practical startup success prediction applications. More model development is needed for increased success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2732e91d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Comparison and Academic Validation\n",
      "Performance Comparison:\n",
      "              Model  Precision  Recall  F1-Score  AUC-ROC\n",
      "Logistic Regression      0.169   0.709     0.273    0.781\n",
      "          SVM (RBF)      0.155   0.689     0.252    0.740\n",
      "            XGBoost      0.234   0.388     0.291    0.790\n",
      "    Academic Target      0.570   0.340     0.430      NaN\n",
      "\n",
      "BEST MODEL: XGBoost\n",
      "F1-Score: 0.291\n",
      "No models exceeded academic F1 target of 43.0%\n"
     ]
    }
   ],
   "source": [
    "# Model Comparison and Academic Validation\n",
    "\n",
    "print(\"Model Comparison and Academic Validation\")\n",
    "\n",
    "# Comparison Table\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['Logistic Regression', 'SVM (RBF)', 'XGBoost', 'Academic Target'],\n",
    "    'Precision': [lr_precision, svm_precision, xgb_precision, TARGET_PRECISION],\n",
    "    'Recall': [lr_recall, svm_recall, xgb_recall, TARGET_RECALL],\n",
    "    'F1-Score': [lr_f1, svm_f1, xgb_f1, TARGET_F1],\n",
    "    'AUC-ROC': [lr_auc, svm_auc, xgb_auc, np.nan]\n",
    "})\n",
    "\n",
    "print(\"Performance Comparison:\")\n",
    "print(results_df.round(3).to_string(index=False))\n",
    "\n",
    "# Identifies the best model\n",
    "best_f1_idx = results_df['F1-Score'][:-1].idxmax()  # Excluded academic target\n",
    "best_model_name = results_df.loc[best_f1_idx, 'Model']\n",
    "best_f1_score = results_df.loc[best_f1_idx, 'F1-Score']\n",
    "\n",
    "print(f\"\\nBEST MODEL: {best_model_name}\")\n",
    "print(f\"F1-Score: {best_f1_score:.3f}\")\n",
    "\n",
    "# Academic Validation Check\n",
    "models_beating_target = results_df[results_df['F1-Score'] > TARGET_F1]['Model'].tolist()\n",
    "if 'Academic Target' in models_beating_target:\n",
    "    models_beating_target.remove('Academic Target')\n",
    "\n",
    "if models_beating_target:\n",
    "    print(f\"Models exceeding academic target: {', '.join(models_beating_target)}\")\n",
    "else:\n",
    "    print(\"No models exceeded academic F1 target of 43.0%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd934de",
   "metadata": {},
   "source": [
    "## 7. Feature Importance Analysis\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "**XGBoost Most Important Features**:\n",
    "\n",
    "1. **Temporal Era**\n",
    "   - era_recovery (18.31%) - Recovery period after dot com crash\n",
    "   - era_post_crash (8.55%) - Post crash era\n",
    "   - era_dotcom_era (5.97%) - Dot-com boom period\n",
    "   - Combined temporal importance: **48.9%** of total feature importance\n",
    "\n",
    "2. **Geographic Location**\n",
    "   - is_usa (7.01%) - Being in the US is a strong predictor\n",
    "   - city_startup_density and region_startup_density also feature prominently\n",
    "   - Total geographic importance: **13.7%**\n",
    "\n",
    "3. **Industry Categories**\n",
    "   - category_biotechnology (5.04%) - Biotech companies stand out\n",
    "   - Various tech categories (web, advertising, health, enterprise) all feature\n",
    "   - Total industry importance: **37.4%**\n",
    "\n",
    "### Logistic Regression Insights (Coefficient Interpretation)\n",
    "\n",
    "**Positive Predictors (Increase Success Probability):**\n",
    "- Being in USA (+0.635)\n",
    "- Advertising category (+0.627)\n",
    "- Analytics category (+0.557)\n",
    "- Mobile category (+0.438)\n",
    "\n",
    "**Negative Predictors (Decrease Success Probability):**\n",
    "- Later founding year (-1.020)\n",
    "   - Earlier companies more successful\n",
    "- Biotechnology (-0.662)\n",
    "   - Contrasts with XGBoost importance\n",
    "- Dot com era (-0.869)\n",
    "   - Was not expected honestly\n",
    "- Health category (-0.593)\n",
    "\n",
    "### Important Observations\n",
    "\n",
    "- **Era Effects Are Crucial:** Nearly 50% of XGBoost's decision making relies on when companies were founded, suggests strong temporal patterns in startup success\n",
    "- **Geographic Advantage:** US location provides a significant advantage, consistent with the concentration of startup ecosystems and venture capital\n",
    "- **Industry Paradoxes:** Biotechnology shows high importance in XGBoost but negative coefficient in Logistic Regression. This suggests complex non linear relationships that tree based models capture better\n",
    "- **Model Differences:** The contrasting signs between XGBoost importance and Logistic Regression coefficients highlight why XGBoost performed better. It can capture complex interactions that linear models miss\n",
    "- This analysis validates XGBoost as the best model, as it's clearly capturing nuanced patterns that the linear logistic regression cannot represent effectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b45ea573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Importance Analysis\n",
      "Top 15 Most Important Features (XGBoost):\n",
      "==================================================\n",
      " 1. era_recovery              0.1831\n",
      " 2. founded_year_std          0.1602\n",
      " 3. era_post_crash            0.0855\n",
      " 4. is_usa                    0.0701\n",
      " 5. era_dotcom_era            0.0597\n",
      " 6. category_biotechnology    0.0504\n",
      " 7. city_startup_density      0.0355\n",
      " 8. category_web              0.0354\n",
      " 9. category_advertising      0.0336\n",
      "10. category_curated          0.0336\n",
      "11. category_health           0.0331\n",
      "12. region_startup_density    0.0317\n",
      "13. category_enterprise       0.0263\n",
      "14. category_technology       0.0258\n",
      "15. category_mobile           0.0224\n",
      "\n",
      "Feature importance by category:\n",
      "- Geographic features: 0.137\n",
      "- Industry features: 0.374\n",
      "- Temporal features: 0.489\n",
      "\n",
      "Logistic Regression - Top Feature Coefficients:\n",
      "Top 20 features by absolute coefficient:\n",
      " 1. founded_year_std          -1.0199\n",
      " 2. era_dotcom_era            -0.8692\n",
      " 3. category_biotechnology    -0.6616\n",
      " 4. is_usa                    +0.6351\n",
      " 5. category_advertising      +0.6274\n",
      " 6. category_health           -0.5929\n",
      " 7. category_analytics        +0.5565\n",
      " 8. category_technology       -0.5193\n",
      " 9. category_mobile           +0.4377\n",
      "10. category_web              +0.4105\n",
      "11. category_enterprise       +0.3986\n",
      "12. category_curated          +0.3678\n",
      "13. category_games            +0.3312\n",
      "14. region_startup_density    +0.2966\n",
      "15. category_marketing        -0.2447\n",
      "16. category_social           +0.2424\n",
      "17. city_startup_density      +0.2318\n",
      "18. category_software         +0.1743\n",
      "19. era_recovery              -0.1263\n",
      "20. category_e-commerce       +0.0484\n"
     ]
    }
   ],
   "source": [
    "# Feature Importance Analysis\n",
    "\n",
    "print(\"Feature Importance Analysis\")\n",
    "\n",
    "# XGBoost feature importance (assumes as best model (it is))\n",
    "if best_model_name == 'XGBoost':\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_train.columns,\n",
    "        'importance': xgb_best.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(\"Top 15 Most Important Features (XGBoost):\")\n",
    "    print(\"=\"*50)\n",
    "    for i, (_, row) in enumerate(feature_importance.head(15).iterrows(), 1):\n",
    "        print(f\"{i:2d}. {row['feature']:<25} {row['importance']:.4f}\")\n",
    "\n",
    "# Feature importance by category\n",
    "print(f\"\\nFeature importance by category:\")\n",
    "geo_importance = feature_importance[feature_importance['feature'].isin(geographic_features)]['importance'].sum()\n",
    "industry_importance = feature_importance[feature_importance['feature'].isin(industry_features)]['importance'].sum()\n",
    "temporal_importance = feature_importance[feature_importance['feature'].isin(temporal_features)]['importance'].sum()\n",
    "\n",
    "print(f\"- Geographic features: {geo_importance:.3f}\")\n",
    "print(f\"- Industry features: {industry_importance:.3f}\")\n",
    "print(f\"- Temporal features: {temporal_importance:.3f}\")\n",
    "\n",
    "# Logistic Regression coefficients (interpretability)\n",
    "print(f\"\\nLogistic Regression - Top Feature Coefficients:\")\n",
    "lr_coef = pd.DataFrame({\n",
    "    'feature': X_train.columns,\n",
    "    'coefficient': lr_best.coef_[0]\n",
    "}).sort_values('coefficient', key=abs, ascending=False)\n",
    "\n",
    "print(\"Top 20 features by absolute coefficient:\")\n",
    "for i, (_, row) in enumerate(lr_coef.head(20).iterrows(), 1):\n",
    "    direction = \"+\" if row['coefficient'] > 0 else \"-\"\n",
    "    print(f\"{i:2d}. {row['feature']:<25} {direction}{abs(row['coefficient']):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11141ade",
   "metadata": {},
   "source": [
    "## 8. Confusion Matrix and Classification Reports\n",
    "\n",
    "\n",
    "### Model Performance Comparison\n",
    "\n",
    "**Logistic Regression**\n",
    "- **Balanced Approach**: Sensitivity (70.9%) ≈ Specificity (70.9%)\n",
    "- **High Recall**: Catches 395 out of 557 successful startups\n",
    "- **Moderate Precision**: 395/(395+1938) = 16.9% precision\n",
    "- **Trade-off**: High false positive rate (1,938 unsuccessful labeled as successful)\n",
    "\n",
    "**SVM (RBF)**\n",
    "- **Similar to Logistic**: Sensitivity (68.9%) ≈ Specificity (68.4%)\n",
    "- **Slightly Worse**: Fewer true positives (384) than Logistic Regression\n",
    "- **Highest False Positives**: 2,101 - the most aggressive in predicting success\n",
    "- **Lowest Precision**: ~15.5%\n",
    "\n",
    "**XGBoost**\n",
    "- **Conservative Approach**: Very high specificity (89.4%) but low sensitivity (38.8%)\n",
    "- **High Precision**: 216/(216+709) = 23.4% - best precision of all models\n",
    "- **Low Recall**: Only catches 216 out of 557 successful startups\n",
    "- **Risk-Averse**: Much fewer false positives (709 vs 1,938+ for others)\n",
    "\n",
    "### Business Implications\n",
    "\n",
    "**Logistic Regression & SVM**: \n",
    "- **Use Case**: To cast a wide net and don't mind investigating many false leads\n",
    "- **Risk**: High chance of wasting resources on unsuccessful startups (high FP rate)\n",
    "- **Benefit**: Won't miss many successful opportunities (high recall)\n",
    "\n",
    "**XGBoost**:\n",
    "- **Use Case**: Limited resources and want high confidence in recommendations\n",
    "- **Risk**: Will miss many successful startups (low recall)\n",
    "- **Benefit**: When prediciton is to invest, it's more likely to be correct (high precision)\n",
    "\n",
    "### Cost Structure Implicaitons\n",
    "\n",
    "- **High Cost of False Negatives** (missing good opportunities): Choose Logistic Regression\n",
    "- **High Cost of False Positives** (investigating bad leads): Choose XGBoost\n",
    "- **Balanced Approach**: Logistic Regression offers the best balance\n",
    "\n",
    "### Future Decisions\n",
    "\n",
    "- XGBoost, despite having the best F1-score, shows a very different risk profile. Its conservative nature (high specificity, low sensitivity) makes it act more like a \"quality filter\" rather than an \"opportunity finder\"\n",
    "- This analysis suggests attempting **ensemble approaches** or **different probability thresholds** to optimize specific business needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd348cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conufsion Matrix and Classfication Reports\n",
      "\n",
      "LOGISTIC REGRESSION:\n",
      "Confusion Matrix:\n",
      "  True Negatives:  4720  |  False Positives: 1938\n",
      "  False Negatives:  162  |  True Positives:   395\n",
      "\n",
      "  Sensitivity (Recall): 0.709\n",
      "  Specificity: 0.709\n",
      "\n",
      "SVM (RBF):\n",
      "Confusion Matrix:\n",
      "  True Negatives:  4557  |  False Positives: 2101\n",
      "  False Negatives:  173  |  True Positives:   384\n",
      "\n",
      "  Sensitivity (Recall): 0.689\n",
      "  Specificity: 0.684\n",
      "\n",
      "XGBOOST:\n",
      "Confusion Matrix:\n",
      "  True Negatives:  5949  |  False Positives:  709\n",
      "  False Negatives:  341  |  True Positives:   216\n",
      "\n",
      "  Sensitivity (Recall): 0.388\n",
      "  Specificity: 0.894\n"
     ]
    }
   ],
   "source": [
    "# Conufsion Matrix and Classfication Reports\n",
    "\n",
    "print(\"Conufsion Matrix and Classfication Reports\")\n",
    "\n",
    "# Confusion Matricies for ALL models\n",
    "models_data = [\n",
    "    ('Logistic Regression', lr_pred, lr_pred_proba),\n",
    "    ('SVM (RBF)', svm_pred, svm_pred_proba),\n",
    "    ('XGBoost', xgb_pred, xgb_pred_proba)\n",
    "]\n",
    "\n",
    "for model_name, predictions, probabilities in models_data:\n",
    "    print(f\"\\n{model_name.upper()}:\")\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(f\"  True Negatives:  {tn:4d}  |  False Positives: {fp:4d}\")\n",
    "    print(f\"  False Negatives: {fn:4d}  |  True Positives:  {tp:4d}\")\n",
    "    \n",
    "    # Additional metrics\n",
    "    specificity = tn / (tn + fp)\n",
    "    sensitivity = tp / (tp + fn)  # Same as recall\n",
    "    \n",
    "    print(f\"\\n  Sensitivity (Recall): {sensitivity:.3f}\")\n",
    "    print(f\"  Specificity: {specificity:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba4b28",
   "metadata": {},
   "source": [
    "## 9. Cross Validation Stability Check\n",
    "\n",
    "### Transformation Applied\n",
    "\n",
    "- **Reduced Fold Strategy Implementation**: Applied 3 fold cross validation instead of standard 5 fold to save time while maintaining statistical validity for stability assessment, reducing total model fits from 15 to 9 per algorithm while preserving meaningful variance estimation capabilities\n",
    "- **Model Generalization Validation Pipeline**: Executed comprehensive stability assessment across all three optimized models using identical F1-score evaluation framework, ensuring consistent performance measurement methodology and enabling direct comparison of cross-validation variance patterns between different algorithmic approaches\n",
    "- **Statistical Variance Quantification**: Calculated mean F1-scores, standard deviations, and performance ranges across validation folds to identify models with robust generalization characteristics versus those exhibiting high sensitivity to training data partition variations that could indicate overfitting or unstable learning\n",
    "- **Production Readiness Assessment Framework**: Evaluated cross-validation consistency as key indicator of deployment reliability, where low variance between folds suggests stable performance across different data distributions and reduced risk of significant performance degradation in production environments\n",
    "\n",
    "### Methodological Rationale\n",
    "\n",
    "- **Computational Efficiency Optimization**: 3 fold cross validation provides sufficient statistical power for stability assessment while reducing computational overhead compared to 5 fold approach, enabling faster validation of multiple models without sacrificing meaningful variance estimation for production deployment decisions\n",
    "- **Generalization Consistency Focus**: Cross validation stability serves as critical indicator of model robustness beyond single test set evaluation, identifying algorithms that maintain consistent performance across different data partitions and reducing risk of deployment failures due to training set idiosyncrasies\n",
    "- **Overfitting Detection Strategy**: High variance between CV folds indicates potential overfitting where models memorize specific training patterns rather than learning generalizable startup success relationships, with stable models demonstrating superior ability to handle unseen data distributions in real world applications\n",
    "- **Business Risk Mitigation**: Consistent cross validation performance provides confidence intervals for expected model behavior in production, enabling stakeholders to understand performance reliability and make informed decisions about model deployment in venture capital investment screening processes\n",
    "\n",
    "### Performance Analysis\n",
    "\n",
    "- **Logistic Regression Stability**: Achieved outstanding consistency with minimal variance (0.265 ± 0.004, range: 0.259-0.269), demonstrating good stability across different data partitions and indicating robust linear relationship capture between founding time features and startup success probability\n",
    "- **SVM Comparable Stability**: Delivered similarly exceptional stability (0.255 ± 0.003, range: 0.252-0.259) with lowest absolute variance among all models, suggesting RBF kernel complexity remains well controlled despite non linear decision boundaries and confirming consistent performance across validation folds\n",
    "- **XGBoost Moderate Variance Pattern**: Exhibited higher but acceptable variance (0.297 ± 0.011, range: 0.281-0.306) reflecting ensemble method complexity where individual tree variations create fold-to-fold performance fluctuations, though range remains within practical deployment tolerance levels\n",
    "- **Cross Validation vs Test Performance Alignment**: All models demonstrated strong alignment between mean CV performance and test set results (LR: 0.265 vs 0.273, SVM: 0.255 vs 0.252, XGB: 0.297 vs 0.291), validating reliable performance estimation and confirming absence of significant overfitting concerns\n",
    "\n",
    "### ML Pipeline Impact\n",
    "\n",
    "- **Production Deployment Confidence**: Exceptional stability across linear models (LR/SVM) provides high confidence for production deployment where consistent performance is critical for business applications, while XGBoost variance remains within acceptable bounds for practical implementation scenarios\n",
    "- **Model Selection Validation**: Stability analysis confirms XGBoost as optimal choice despite higher variance, as superior mean performance (0.297) combined with acceptable consistency range supports its selection for best overall startup success prediction capability\n",
    "- **Ensemble Strategy Implications**: Low variance linear models provide excellent candidates for ensemble combinations where stability is prioritized, while XGBoost's higher performance with moderate variance suggests potential for threshold optimization or model averaging approaches\n",
    "- **Risk Assessment Framework**: Variance patterns enable quantitative risk assessment for stakeholder communication, where Logistic Regression offers most predictable performance (±0.004 variation) while XGBoost provides higher average returns with acceptable uncertainty (±0.011 variation)\n",
    "- **Cross-Validation Methodology Validation**: Strong alignment between 3 fold CV estimates and test performance validates reduced fold approach effectiveness, enabling faster model development cycles while maintaining robust performance estimation for iterative improvement processes\n",
    "- **Business Implementation Guidance**: Stability results support different deployment strategies: Logistic Regression for conservative risk averse applications requiring consistent performance, XGBoost for aggressive opportunity identification where higher average performance justifies moderate variance acceptance in venture capital screening scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83f3febe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Stability Check\n",
      "Logistic Regression:\n",
      "- CV F1 Scores: ['0.269', '0.259', '0.266']\n",
      "- Mean: 0.265 ± 0.004\n",
      "- Range: 0.259 - 0.269\n",
      "SVM (RBF):\n",
      "- CV F1 Scores: ['0.254', '0.252', '0.259']\n",
      "- Mean: 0.255 ± 0.003\n",
      "- Range: 0.252 - 0.259\n",
      "XGBoost:\n",
      "- CV F1 Scores: ['0.306', '0.281', '0.304']\n",
      "- Mean: 0.297 ± 0.011\n",
      "- Range: 0.281 - 0.306\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Stability Check\n",
    "\n",
    "print(\"Cross Validation Stability Check\")\n",
    "\n",
    "# Checks CV score stability for best models\n",
    "def cv_stability_check(model, X, y, model_name):\n",
    "    \"\"\"Check cross-validation stability using 3-fold CV\"\"\"\n",
    "    cv_scores = cross_val_score(model, X, y, cv=3, scoring='f1')\n",
    "    \n",
    "    print(f\"{model_name}:\")\n",
    "    print(f\"- CV F1 Scores: {[f'{score:.3f}' for score in cv_scores]}\")\n",
    "    print(f\"- Mean: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "    print(f\"- Range: {cv_scores.min():.3f} - {cv_scores.max():.3f}\")\n",
    "    \n",
    "    return cv_scores\n",
    "\n",
    "# Checks stability for ALL models using 3-fold CV (to save a lot of time)\n",
    "lr_cv_scores = cv_stability_check(lr_best, X_train, y_train, \"Logistic Regression\")\n",
    "svm_cv_scores = cv_stability_check(svm_best, X_train_scaled, y_train, \"SVM (RBF)\")\n",
    "xgb_cv_scores = cv_stability_check(xgb_best, X_train, y_train, \"XGBoost\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded6b15d",
   "metadata": {},
   "source": [
    "## 10. Saving Models and Results\n",
    "\n",
    "**Purpose**: Persist trained models and evaluation results for future use and deployment\n",
    "\n",
    "### Key Operations\n",
    "- **Model Serialization**: Save all three trained models using joblib for efficient storage and loading\n",
    "- **Results Documentation**: Export performance metrics and feature analysis to CSV format\n",
    "- **Organized Structure**: Models saved to ../results/models/, results to ../results/ directory\n",
    "\n",
    "### Models Saved\n",
    "- **Logistic Regression** (logistic_regression_best.pkl) - Best linear baseline with L1 regularization\n",
    "- **SVM with RBF Kernel** (svm_rbf_best.pkl) - Non linear classifier with balanced class weights  \n",
    "- **XGBoost** (xgboost_best.pkl) - Best performing ensemble model with optimal hyperparameters\n",
    "\n",
    "### Results Exported\n",
    "- **Model Comparison** (baseline_model_comparison.csv) - Performance metrics across all algorithms\n",
    "- **Feature Importance** (feature_importance_xgboost.csv) - XGBoost feature rankings and scores\n",
    "\n",
    "### Output Summary\n",
    "- **Best Model**: XGBoost with F1-Score of 0.291\n",
    "- **Models Directory**: 3 trained models\n",
    "- **Results Files**: Performance benchmarks and feature analysis preserved for reporting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa196516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving Models and Results\n",
      "Models saved to ../results/models/\n",
      "Results saved to ../results/\n"
     ]
    }
   ],
   "source": [
    "# Saving Models and Results\n",
    "\n",
    "print(\"Saving Models and Results\")\n",
    "\n",
    "# Models directory\n",
    "os.makedirs('../results/models', exist_ok=True)\n",
    "\n",
    "# Saves best models\n",
    "joblib.dump(lr_best, '../results/models/logistic_regression_best.pkl')\n",
    "joblib.dump(svm_best, '../results/models/svm_rbf_best.pkl')\n",
    "joblib.dump(xgb_best, '../results/models/xgboost_best.pkl')\n",
    "\n",
    "# Saves results\n",
    "results_df.to_csv('../results/baseline_model_comparison.csv', index=False)\n",
    "feature_importance.to_csv('../results/feature_importance_xgboost.csv', index=False)\n",
    "\n",
    "print(\"Models saved to ../results/models/\")\n",
    "print(\"Results saved to ../results/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
